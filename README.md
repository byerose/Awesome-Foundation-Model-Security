> introducution

# Table of Contents
- [Paper list](#Paper-list)
  - [Survey](#survey)
  - [Risks of Model](#Risks-of-Model)
    - [Poisoning](#Poisoning)
    - [Privacy](#Privacy)
  - [Evaluation on Content](#Evaluation-on-Content)
- [Workshop](#Workshop)

# Paper list

## Survey

## Risks of Model

### Poisoning
- [BadGPT: Exploring Security Vulnerabilities of ChatGPT via Backdoor Attacks to InstructGPT](https://arxiv.org/abs/2304.12298) [**NDSS Poster**]
- [Analyzing And Editing Inner Mechanisms of Backdoored Language Models](http://arxiv.org/abs/2302.12461) [**ArXiv**] 

### Privacy
- [Multi-step Jailbreaking Privacy Attacks on ChatGPT](http://arxiv.org/abs/2304.05197) [**ArXiv**]

## Evaluation on Content
- [LEVER: Learning to Verify Language-to-Code Generation with Execution](https://arxiv.org/abs/2302.08468) [**ArXiv**]

# Workshop
- [Challenges of Deploying Generative AI](https://deployinggenerativeai.github.io/index) [**ICML2023**]
